{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scenes Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Tải bộ dữ liệu: Các bạn tải bộ dữ liệu img_cls_scenes_classification.zip trong\n",
    "đường dẫn thuộc mục Datasets tại phần III (trong tập lý thuyết).\n",
    "2. Import các thư viện cần thiết:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset , DataLoader\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Cố định giá trị ngẫu nhiên:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "seed = 59\n",
    "set_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Đọc dữ liệu: Sau khi tải và giải nén bộ dữ liệu, chúng ta sẽ được một thư mục chứa\n",
    "dữ liệu như trong file thuyết minh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So với bộ dữ liệu ở bài trước, ta đã được chia sẵn hai bộ dữ liệu train và val. Tuy\n",
    "nhiên, để đồng bộ, chúng ta sẽ vẫn đi theo hướng code cũ. Đầu tiên, ta vẫn đọc danh\n",
    "sách classes như sau:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = 'scenes_classification '\n",
    "train_dir = os.path.join(root_dir , 'train')\n",
    "test_dir = os.path.join(root_dir , 'val')\n",
    "\n",
    "classes = {\n",
    "label_idx: class_name \\\n",
    "for label_idx , class_name in enumerate(\n",
    "sorted(os.listdir(train_dir))\n",
    ")\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tiếp đến, ta đọc lên toàn bộ các đường dẫn ảnh cũng như label tương ứng. Tuy nhiên,\n",
    "ta sẽ coi thư mục val là tập test của bộ dữ liệu và sẽ khai báo danh sách riêng cho bộ\n",
    "này. Như vậy, ta có code như sau:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = []\n",
    "y_train = []\n",
    "X_test = []\n",
    "y_test = []\n",
    "\n",
    "for dataset_path in [train_dir , test_dir ]:\n",
    "for label_idx , class_name in classes.items():\n",
    "class_dir = os.path.join(dataset_path , class_name)\n",
    "for img_filename in os.listdir(class_dir):\n",
    "img_path = os.path.join(class_dir , img_filename)\n",
    "if 'train' in dataset_path:\n",
    "X_train.append(img_path)\n",
    "y_train.append(label_idx)\n",
    "else:\n",
    "X_test.append(img_path)\n",
    "y_test.append(label_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Chia bộ dữ liệu train, val, test: Vì đã có sẵn bộ dữ liệu train và test, ta chỉ việc\n",
    "chia thêm cho tập val từ tập train như sau:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 0\n",
    "val_size = 0.2\n",
    "is_shuffle = True\n",
    "\n",
    "X_train , X_val , y_train , y_val = train_test_split(\n",
    "X_train , y_train ,\n",
    "test_size=val_size ,\n",
    "random_state=seed ,\n",
    "shuffle=is_shuffle\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Xây dựng class pytorch datasets: Tương tự ở bài trước, ta xây dựng pytorch\n",
    "dataset cho bộ dữ liệu Scenes như sau:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScenesDataset(Dataset):\n",
    "def __init__(\n",
    "self ,\n",
    "X, y,\n",
    "transform=None\n",
    "):\n",
    "self.transform = transform\n",
    "self.img_paths = X\n",
    "self.labels = y\n",
    "\n",
    "def __len__(self):\n",
    "return len(self.img_paths)\n",
    "\n",
    "def __getitem__(self , idx):\n",
    "img_path = self.img_paths[idx]\n",
    "img = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "if self.transform:\n",
    "img = self.transform(img)\n",
    "\n",
    "return img , self.labels[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Xây dựng hàm tiền xử lý ảnh (transforms): Tương tự như bài trước, ta xây\n",
    "dựng hàm tiền xử lý ảnh như sau:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(img , img_size =(224 , 224)):\n",
    "img = img.resize(img_size)\n",
    "img = np.array(img)[..., :3]\n",
    "img = torch.tensor(img).permute(2, 0, 1).float ()\n",
    "normalized_img = img / 255.0\n",
    "\n",
    "return normalized_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Khai báo datasets object cho ba bộ train, val, test: Tương tự như bài trên, ta\n",
    "khai báo ba object datasets tương ứng cho ba bộ dữ liệu train, val, test như sau:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ScenesDataset(\n",
    "X_train , y_train ,\n",
    "transform=transform\n",
    ")\n",
    "val_dataset = ScenesDataset(\n",
    "X_val , y_val ,\n",
    "transform=transform\n",
    ")\n",
    "test_dataset = ScenesDataset(\n",
    "X_test , y_test ,\n",
    "transform=transform\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Khai báo dataloader: Lưu ý, với colab, các bạn nên cài đặt train batch size = 64\n",
    "để có thể train được bài này."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batch_size = 64\n",
    "test_batch_size = 8\n",
    "\n",
    "train_loader = DataLoader(\n",
    "train_dataset ,\n",
    "batch_size=train_batch_size ,\n",
    "shuffle=True\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "val_dataset ,\n",
    "batch_size=test_batch_size ,\n",
    "shuffle=False\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "test_dataset ,\n",
    "batch_size=test_batch_size ,\n",
    "shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. Xây dựng model: Trong phần này, chúng ta sẽ xây dựng class cho model deep\n",
    "learning với kiến trúc DenseNet. Thông tin tổng quan về kiến trúc DenseNet được thể\n",
    "hiện ở bảng trong thuyết minh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Đầu tiên, chúng ta sẽ xây dựng class Dense Block, có ảnh mô phỏng như hình dưới\n",
    "đây:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BottleneckBlock(nn.Module):\n",
    "def __init__(self , in_channels , growth_rate):\n",
    "super(BottleneckBlock , self).__init__ ()\n",
    "self.bn1 = nn.BatchNorm2d(in_channels)\n",
    "self.conv1 = nn.Conv2d(in_channels , 4 * growth_rate ,kernel_size =1, bias=False)\n",
    "self.bn2 = nn.BatchNorm2d (4 * growth_rate)\n",
    "self.conv2 = nn.Conv2d (4 * growth_rate , growth_rate ,kernel_size =3, padding=1, bias=False)\n",
    "self.relu = nn.ReLU()\n",
    "\n",
    "def forward(self , x):\n",
    "res = x.clone().detach ()\n",
    "x = self.bn1(x)\n",
    "x = self.relu(x)\n",
    "x = self.conv1(x)\n",
    "x = self.bn2(x)\n",
    "x = self.relu(x)\n",
    "x = self.conv2(x)\n",
    "x = torch.cat([res , x], 1)\n",
    "\n",
    "return x\n",
    "\n",
    "class DenseBlock(nn.Module):\n",
    "def __init__(self , num_layers , in_channels , growth_rate):\n",
    "super(DenseBlock , self).__init__ ()\n",
    "layers = []\n",
    "for i in range(num_layers):\n",
    "layers.append(BottleneckBlock(in_channels + i *growth_rate , growth_rate))\n",
    "self.block = nn.Sequential (* layers)\n",
    "\n",
    "def forward(self , x):\n",
    "    return self.block(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Với DenseBlock, ta triển khai toàn bộ kiến trúc DenseNet như sau:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseNet(nn.Module):\n",
    "def __init__(self , num_blocks , growth_rate , num_classes):\n",
    "super(DenseNet , self).__init__ ()\n",
    "self.conv1 = nn.Conv2d(3, 2 * growth_rate , kernel_size =7,padding=3, stride=2, bias=False)\n",
    "self.bn1 = nn.BatchNorm2d (2 * growth_rate)\n",
    "self.pool1 = nn.MaxPool2d(kernel_size =3, stride=2, padding =1)\n",
    "\n",
    "self.dense_blocks = nn.ModuleList ()\n",
    "in_channels = 2 * growth_rate\n",
    "for i, num_layers in enumerate(num_blocks):\n",
    "self.dense_blocks.append(DenseBlock(num_layers ,in_channels , growth_rate))\n",
    "in_channels += num_layers * growth_rate\n",
    "if i != len(num_blocks) - 1:\n",
    "out_channels = in_channels // 2\n",
    "self.dense_blocks.append(nn.Sequential(\n",
    "nn.BatchNorm2d(in_channels),\n",
    "nn.Conv2d(in_channels , out_channels , kernel_size=1, bias=False),\n",
    "nn.AvgPool2d(kernel_size =2, stride =2)\n",
    "))\n",
    "in_channels = out_channels\n",
    "\n",
    "self.bn2 = nn.BatchNorm2d(in_channels)\n",
    "self.pool2 = nn.AvgPool2d(kernel_size =7)\n",
    "self.relu = nn.ReLU()\n",
    "self.fc = nn.Linear(in_channels , num_classes)\n",
    "\n",
    "def forward(self , x):\n",
    "x = self.conv1(x)\n",
    "x = self.bn1(x)\n",
    "x = self.relu(x)\n",
    "x = self.pool1(x)\n",
    "\n",
    "for block in self.dense_blocks:\n",
    "x = block(x)\n",
    "\n",
    "x = self.bn2(x)\n",
    "x = self.relu(x)\n",
    "x = self.pool2(x)\n",
    "x = x.view(x.size (0), -1)\n",
    "x = self.fc(x)\n",
    "\n",
    "return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cuối cùng, khai báo model DenseNet bằng đoạn code sau (ở đây ta sẽ sử dụng phiên\n",
    "bản DenseNet-121)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = len(list(classes.keys()))\n",
    "device = 'cuda' if torch.cuda.is_available () else 'cpu'\n",
    "\n",
    "model = DenseNet(\n",
    "    [6, 12, 24, 16],\n",
    "growth_rate =32,\n",
    "num_classes=n_classes\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11. Khai báo hàm loss và thuật toán huấn luyện: Với bài toán là phân loại ảnh, ta\n",
    "cũng sẽ sử dụng hàm loss CrossEntropy và Stochastic Gradient:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-2\n",
    "epochs = 15\n",
    "\n",
    "criterion = nn.CrossEntropyLoss ()\n",
    "optimizer = torch.optim.SGD(\n",
    "model.parameters (),\n",
    "lr=lr\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12. Thực hiện huấn luyện: Sử dụng hàm evaluate() và hàm fit() đã triển khai trong\n",
    "bài trước, chúng ta sẽ huấn luyện model DenseNet như sau:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses , val_losses = fit(\n",
    "model ,\n",
    "train_loader ,\n",
    "val_loader ,\n",
    "criterion ,\n",
    "optimizer ,\n",
    "device ,\n",
    "epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13. Đánh giá model: Ta gọi hàm evaluate() để đánh giá performance của model trên\n",
    "hai tập val và test như sau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loss , val_acc = evaluate(\n",
    "model ,\n",
    "val_loader ,\n",
    "criterion ,\n",
    "device\n",
    ")\n",
    "test_loss , test_acc = evaluate(\n",
    "model ,\n",
    "test_loader ,\n",
    "criterion ,\n",
    "device\n",
    ")\n",
    "\n",
    "print('Evaluation on val/test dataset ')\n",
    "print('Val accuracy: ', val_acc)\n",
    "print('Test accuracy: ', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Triển khai mô hình: Với hai mô hình về phân loại ảnh thời tiết và phân loại ảnh phong\n",
    "cảnh đã huấn luyện được ở phía trên, chúng ta có thể triển khai lên streamlit như ảnh sau\n",
    "(thông tin về code cài đặt và link web streamlit được đề cập tại phần III trong thuyết minh):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
