{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weather Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Tải bộ dữ liệu: Các bạn tải bộ dữ liệu img_cls_weather_dataset.zip trong\n",
    "đường dẫn thuộc mục Datasets tại phần III.\n",
    "2. Import các thư viện cần thiết: Trong bài tập này, chúng ta sẽ sử dụng thư viện\n",
    "PyTorch để xây dựng và huấn luyện mô hình deep learning. Thêm vào đó, vì làm việc\n",
    "liên quan đến dữ liệu ảnh, chúng ta sẽ sử dụng thư viện PIL để xử lý"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1784868064.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[2], line 2\u001b[1;36m\u001b[0m\n\u001b[1;33m    2 import torch.nn as nn\u001b[0m\n\u001b[1;37m      ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset , DataLoader\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Cố định giá trị ngẫu nhiên: Để có thể tái tạo lại cùng một kết quả mô hình, chúng\n",
    "ta sẽ cố định cùng một giá trị ngẫu nhiên (seed) cho các thư viện có chứa các hàm\n",
    "tạo giá trị ngẫu nhiên:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "seed = 59\n",
    "set_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Đọc dữ liệu: Sau khi tải và giải nén bộ dữ liệu, chúng ta sẽ được một thư mục chứa\n",
    "dữ liệu như sau:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Để thuận tiện trong việc xây dựng PyTorch datasets, chúng ta sẽ ghi nhận thông tin\n",
    "về các classes, đường dẫn đến tất cả các ảnh cũng như label tương ứng như sau. Nhận\n",
    "thấy tên của các folder con trong thư mục weather-dataset/dataset cũng là tên class.\n",
    "Vì vậy, chúng ta sẽ đọc tên các folder này và đưa vào một dictionary như sau:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = 'weather -dataset/dataset '\n",
    "img_paths = []\n",
    "labels = []\n",
    "classes = {\n",
    "label_idx: class_name \\\n",
    "for label_idx , class_name in enumerate(\n",
    "sorted(os.listdir(root_dir))\n",
    ")\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sau đó, ta đọc toàn bộ đường dẫn của các ảnh trong bộ dữ liệu cũng như label tương\n",
    "ứng:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_paths = []\n",
    "labels = []\n",
    "for label_idx , class_name in classes.items():\n",
    "class_dir = os.path.join(root_dir , class_name)\n",
    "for img_filename in os.listdir(class_dir):\n",
    "img_path = os.path.join(class_dir , img_filename)\n",
    "img_paths.append(img_path)\n",
    "labels.append(label_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Chia bộ dữ liệu train, val, test: Với danh sách đường dẫn ảnh và label, chúng ta\n",
    "sẽ chia thành ba bộ dữ liệu train, val, test sử dụng hàm train_test_split() của thư\n",
    "viện scikit-learn như sau:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_size = 0.2\n",
    "test_size = 0.125\n",
    "is_shuffle = True\n",
    "\n",
    "X_train , X_val , y_train , y_val = train_test_split(\n",
    "img_paths , labels ,\n",
    "test_size=val_size ,\n",
    "random_state=seed ,\n",
    "shuffle=is_shuffle\n",
    ")\n",
    "\n",
    "X_train , X_test , y_train , y_test = train_test_split(\n",
    "X_train , y_train ,\n",
    "test_size=val_size ,\n",
    "random_state=seed ,\n",
    "shuffle=is_shuffle\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Xây dựng class pytorch datasets: Chúng ta xây dựng class datasets cho bộ dữ\n",
    "liệu weather như sau:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeatherDataset(Dataset):\n",
    "def __init__(\n",
    "self ,\n",
    "X, y,\n",
    "transform=None\n",
    "):\n",
    "self.transform = transform\n",
    "self.img_paths = X\n",
    "self.labels = y\n",
    "\n",
    "def __len__(self):\n",
    "return len(self.img_paths)\n",
    "\n",
    "def __getitem__(self , idx):\n",
    "img_path = self.img_paths[idx]\n",
    "img = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "if self.transform:\n",
    "img = self.transform(img)\n",
    "\n",
    "return img , self.labels[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Xây dựng hàm tiền xử lý ảnh (transform): Để đảm bảo dữ liệu ảnh đầu vào\n",
    "được đồng bộ về kích thước và giá trị, chúng ta tự định nghĩa hàm transform để tiền\n",
    "xử lý ảnh đầu vào như sau (không sử dụng thư viện torchvision.transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(img , img_size =(224 , 224)):\n",
    "img = img.resize(img_size)\n",
    "img = np.array(img)[..., :3]\n",
    "img = torch.tensor(img).permute(2, 0, 1).float ()\n",
    "normalized_img = img / 255.0\n",
    "\n",
    "return normalized_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Các kỹ thuật được áp dụng: resize ảnh, đổi về tensor và chuẩn hóa giá trị pixel về\n",
    "khoảng (0, 1)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Khai báo datasets object cho ba bộ train, val, test: Với class WeatherDataset\n",
    "và hàm chuẩn hóa ảnh, ta tạo ba object datasets tương ứng như sau:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = WeatherDataset(\n",
    "X_train , y_train ,\n",
    "transform=transform\n",
    ")\n",
    "val_dataset = WeatherDataset(\n",
    "X_val , y_val ,\n",
    "transform=transform\n",
    ")\n",
    "test_dataset = WeatherDataset(\n",
    "X_test , y_test ,\n",
    "transform=transform\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Khai báo dataloader: Với ba object datasets trên, ta khai báo giá trị batch size và\n",
    "tạo dataloader như sau:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batch_size = 512\n",
    "test_batch_size = 8\n",
    "\n",
    "train_loader = DataLoader(\n",
    "train_dataset ,\n",
    "batch_size=train_batch_size ,\n",
    "shuffle=True\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "val_dataset ,\n",
    "batch_size=test_batch_size ,\n",
    "shuffle=False\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "test_dataset ,\n",
    "batch_size=test_batch_size ,\n",
    "shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. Xây dựng model: Trong phần này, chúng ta sẽ xây dựng class cho model deep\n",
    "learning với kiến trúc ResNet. Thông tin tổng quan về kiến trúc ResNet được thể hiện\n",
    "ở bảng ở phần tài liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "def __init__(self , in_channels , out_channels , stride =1):\n",
    "super(ResidualBlock , self).__init__ ()\n",
    "self.conv1 = nn.Conv2d(in_channels , out_channels , kernel_size=3, stride=stride , padding =1)\n",
    "self.batch_norm1 = nn.BatchNorm2d(out_channels)\n",
    "self.conv2 = nn.Conv2d(out_channels , out_channels ,kernel_size =3, stride=1, padding =1)\n",
    "self.batch_norm2 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "self.downsample = nn.Sequential ()\n",
    "if stride != 1 or in_channels != out_channels:\n",
    "self.downsample = nn.Sequential(\n",
    "nn.Conv2d(in_channels , out_channels , kernel_size =1,stride=stride),\n",
    "nn.BatchNorm2d(out_channels)\n",
    ")\n",
    "self.relu = nn.ReLU()\n",
    "\n",
    "def forward(self , x):\n",
    "shortcut = x.clone ()\n",
    "x = self.conv1(x)\n",
    "x = self.batch_norm1(x)\n",
    "x = self.relu(x)\n",
    "x = self.conv2(x)\n",
    "x = self.batch_norm2(x)\n",
    "x += self.downsample(shortcut)\n",
    "x = self.relu(x)\n",
    "\n",
    "return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Với ResidualBlock, ta triển khai toàn bộ kiến trúc ResNet như sau:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "def __init__(self , residual_block , n_blocks_lst , n_classes):\n",
    "super(ResNet , self).__init__ ()\n",
    "self.conv1 = nn.Conv2d(3, 64, kernel_size =7, stride=2,padding =3)\n",
    "self.batch_norm1 = nn.BatchNorm2d (64)\n",
    "self.relu = nn.ReLU()\n",
    "self.maxpool = nn.MaxPool2d(kernel_size =3, stride=2, padding=1)\n",
    "self.conv2 = self.create_layer(residual_block , 64, 64,n_blocks_lst [0], 1)\n",
    "self.conv3 = self.create_layer(residual_block , 64, 128,n_blocks_lst [1], 2)\n",
    "self.conv4 = self.create_layer(residual_block , 128, 256,n_blocks_lst [2], 2)\n",
    "self.conv5 = self.create_layer(residual_block , 256, 512,n_blocks_lst [3], 2)\n",
    "self.avgpool = nn.AdaptiveAvgPool2d (1)\n",
    "self.flatten = nn.Flatten ()\n",
    "self.fc1 = nn.Linear (512, n_classes)\n",
    "\n",
    "def create_layer(self , residual_block , in_channels , out_channels ,n_blocks , stride):\n",
    "blocks = []\n",
    "first_block = residual_block(in_channels , out_channels ,stride)\n",
    "blocks.append(first_block)\n",
    "\n",
    "for idx in range(1, n_blocks):\n",
    "block = residual_block(out_channels , out_channels , stride)\n",
    "blocks.append(block)\n",
    "\n",
    "block_sequential = nn.Sequential (* blocks)\n",
    "\n",
    "return block_sequential\n",
    "\n",
    "def forward(self , x):\n",
    "x = self.conv1(x)\n",
    "x = self.batch_norm1(x)\n",
    "x = self.maxpool(x)\n",
    "x = self.relu(x)\n",
    "x = self.conv2(x)\n",
    "x = self.conv3(x)\n",
    "x = self.conv4(x)\n",
    "x = self.conv5(x)\n",
    "x = self.avgpool(x)\n",
    "x = self.flatten(x)\n",
    "x = self.fc1(x)\n",
    "\n",
    "return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cuối cùng, khai báo model ResNet bằng đoạn code sau:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = len(list(classes.keys()))\n",
    "device = 'cuda' if torch.cuda.is_available () else 'cpu'\n",
    "\n",
    "model = ResNet(\n",
    "residual_block=ResidualBlock ,\n",
    "n_blocks_lst =[2, 2, 2, 2],\n",
    "n_classes=n_classes\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11. Xây dựng hàm đánh giá model: Ta xây dựng hàm đánh giá model với đầu vào\n",
    "là model, bộ dữ liệu đánh giá và hàm loss. Hàm này sẽ trả về giá trị loss và accuracy\n",
    "của model trên tập dữ liệu đầu vào:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model , dataloader , criterion , device):\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "losses = []\n",
    "with torch.no_grad ():\n",
    "for inputs , labels in dataloader:\n",
    "inputs , labels = inputs.to(device), labels.to(device)\n",
    "outputs = model(inputs)\n",
    "loss = criterion(outputs , labels)\n",
    "losses.append(loss.item())\n",
    "_, predicted = torch.max(outputs.data , 1)\n",
    "total += labels.size (0)\n",
    "correct += (predicted == labels).sum().item()\n",
    "\n",
    "loss = sum(losses) / len(losses)\n",
    "acc = correct / total\n",
    "\n",
    "return loss , acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12. Xây dựng hàm huấn luyện model: Ta triển khai xây dựng hàm huấn luyện mô\n",
    "hình như sau:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(\n",
    "model ,\n",
    "train_loader ,\n",
    "val_loader ,\n",
    "criterion ,\n",
    "optimizer ,\n",
    "device ,\n",
    "epochs\n",
    "):\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "batch_train_losses = []\n",
    "\n",
    "model.train()\n",
    "for idx , (inputs , labels) in enumerate(train_loader):\n",
    "inputs , labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "optimizer.zero_grad ()\n",
    "outputs = model(inputs)\n",
    "loss = criterion(outputs , labels)\n",
    "loss.backward ()\n",
    "optimizer.step()\n",
    "\n",
    "batch_train_losses.append(loss.item())\n",
    "\n",
    "train_loss = sum(batch_train_losses) / len(batch_train_losses)\n",
    "train_losses.append(train_loss)\n",
    "\n",
    "val_loss , val_acc = evaluate(\n",
    "model , val_loader ,\n",
    "criterion , device\n",
    ")\n",
    "val_losses.append(val_loss)\n",
    "\n",
    "print(f'EPOCH {epoch + 1}:\\ tTrain loss: {train_loss :.4f}\\tValloss: {val_loss :.4f}')\n",
    "\n",
    "return train_losses , val_losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13. Khai báo hàm loss và thuật toán tối ưu hóa: Với bài toán phân loại ảnh, ta sử\n",
    "dụng hàm loss CrossEntropyLoss và thuật toán tối ưu hóa Stochastic Gradient\n",
    "Descent (SGD). Ngoài ra, ta cũng khai báo giá trị learning rate và số epochs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-2\n",
    "epochs = 25\n",
    "\n",
    "criterion = nn.CrossEntropyLoss ()\n",
    "optimizer = torch.optim.SGD(\n",
    "model.parameters (),\n",
    "lr=lr\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "14. Thực hiện huấn luyện: Với tất cả các tham số đầu vào đã sẵn sàng, ta gọi hàm\n",
    "fit() để bắt đầu quá trình huấn luyện mô hình ResNet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses , val_losses = fit(\n",
    "model ,\n",
    "train_loader ,\n",
    "val_loader ,\n",
    "criterion ,\n",
    "optimizer ,\n",
    "device ,\n",
    "epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "15. Đánh giá mô hình: Ta gọi hàm evaluate() để đánh giá performance của model trên\n",
    "hai tập val và test như sau:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loss , val_acc = evaluate(\n",
    "model ,\n",
    "val_loader ,\n",
    "criterion ,\n",
    "device\n",
    ")\n",
    "test_loss , test_acc = evaluate(\n",
    "model ,\n",
    "test_loader ,\n",
    "criterion ,\n",
    "device\n",
    ")\n",
    "\n",
    "print('Evaluation on val/test dataset ')\n",
    "print('Val accuracy: ', val_acc)\n",
    "print('Test accuracy: ', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
