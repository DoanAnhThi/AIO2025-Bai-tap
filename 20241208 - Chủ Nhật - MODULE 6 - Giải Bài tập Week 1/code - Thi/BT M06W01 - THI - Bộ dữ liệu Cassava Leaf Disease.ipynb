{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TẢI VỀ BỘ DỮ LIỆU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget --no-check -certificate https :// storage.googleapis.com/emcassavadata/cassavaleafdata.zip \\\n",
    "-O /content/cassavaleafdata.zip\n",
    "!unzip /content/cassavaleafdata.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "# Import libs\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "\n",
    "from torchsummary import summary\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TIỀN XỬ LÝ DỮ LIỆU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block after function definition on line 8 (509972872.py, line 9)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[2], line 9\u001b[1;36m\u001b[0m\n\u001b[1;33m    return Image.open(path)\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m expected an indented block after function definition on line 8\n"
     ]
    }
   ],
   "source": [
    "data_paths = {\n",
    "'train ': './ train',\n",
    "'valid ': './ validation ',\n",
    "'test': './test'\n",
    "}\n",
    "\n",
    "# load image from path\n",
    "def loader(path):\n",
    "    return Image.open(path)\n",
    "\n",
    "img_size = 150\n",
    "train_transforms = transforms.Compose ([\n",
    "transforms.Resize ((150 , 150)),\n",
    "transforms.ToTensor (),\n",
    "])\n",
    "\n",
    "train_data = datasets.ImageFolder(\n",
    "root=data_paths['train '],\n",
    "loader=loader ,\n",
    "transform=train_transforms\n",
    ")\n",
    "valid_data = datasets.ImageFolder(\n",
    "root=data_paths['valid '],\n",
    "transform=train_transforms\n",
    ")\n",
    "test_data = datasets.ImageFolder(\n",
    "root=data_paths['test'],\n",
    "transform=train_transforms\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XÂY DỰNG MÔ HÌNH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNetClassifier(nn.Module):\n",
    "def __init__(self , num_classes):\n",
    "super().__init__ ()\n",
    "self.conv1 = nn.Conv2d(\n",
    "in_channels =3, out_channels =6, kernel_size =5, padding='same'\n",
    ")\n",
    "self.avgpool1 = nn.AvgPool2d(kernel_size =2)\n",
    "self.conv2 = nn.Conv2d(in_channels =6, out_channels =16, kernel_size =5)\n",
    "self.avgpool2 = nn.AvgPool2d(kernel_size =2)\n",
    "self.flatten = nn.Flatten ()\n",
    "self.fc_1 = nn.Linear (16 * 35 * 35, 120)\n",
    "self.fc_2 = nn.Linear (120, 84)\n",
    "self.fc_3 = nn.Linear (84, num_classes)\n",
    "\n",
    "def forward(self , inputs):\n",
    "outputs = self.conv1(inputs)\n",
    "outputs = self.avgpool1(outputs)\n",
    "outputs = F.relu(outputs)\n",
    "outputs = self.conv2(outputs)\n",
    "outputs = self.avgpool2(outputs)\n",
    "outputs = F.relu(outputs)\n",
    "outputs = self.flatten(outputs)\n",
    "outputs = self.fc_1(outputs)\n",
    "outputs = self.fc_2(outputs)\n",
    "outputs = self.fc_3(outputs)\n",
    "return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HUẤN LUYỆN MÔ HÌNH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training function\n",
    "def train(model , optimizer , criterion , train_dataloader , device , epoch=0, log_interval=50):\n",
    "model.train()\n",
    "total_acc , total_count = 0, 0\n",
    "losses = []\n",
    "start_time = time.time()\n",
    "\n",
    "for idx , (inputs , labels) in enumerate(train_dataloader):\n",
    "    inputs = inputs.to(device)\n",
    "labels = labels.to(device)\n",
    "\n",
    "optimizer.zero_grad ()\n",
    "\n",
    "predictions = model(inputs)\n",
    "\n",
    "# compute loss\n",
    "loss = criterion(predictions , labels)\n",
    "losses.append(loss.item())\n",
    "\n",
    "# backward\n",
    "loss.backward ()\n",
    "torch.nn.utils.clip_grad_norm_(model.parameters (), 0.1)\n",
    "optimizer.step()\n",
    "total_acc += (predictions.argmax (1) == labels).sum().item()\n",
    "total_count += labels.size (0)\n",
    "if idx % log_interval == 0 and idx > 0:\n",
    "elapsed = time.time() - start_time\n",
    "print(\n",
    "\"| epoch {:3d} | {:5d}/{:5d} batches \"\n",
    "\"| accuracy {:8.3f}\".format(\n",
    "epoch , idx , len(train_dataloader), total_acc / total_count\n",
    ")\n",
    ")\n",
    "total_acc , total_count = 0, 0\n",
    "start_time = time.time()\n",
    "\n",
    "epoch_acc = total_acc / total_count\n",
    "epoch_loss = sum(losses) / len(losses)\n",
    "return epoch_acc , epoch_loss\n",
    "\n",
    "# Evaluation function\n",
    "def evaluate(model , criterion , valid_dataloader):\n",
    "model.eval()\n",
    "total_acc , total_count = 0, 0\n",
    "losses = []\n",
    "\n",
    "with torch.no_grad ():\n",
    "for idx , (inputs , labels) in enumerate(valid_dataloader):\n",
    "inputs = inputs.to(device)\n",
    "labels = labels.to(device)\n",
    "\n",
    "predictions = model(inputs)\n",
    "\n",
    "loss = criterion(predictions , labels)\n",
    "losses.append(loss.item())\n",
    "\n",
    "total_acc += (predictions.argmax (1) == labels).sum().item()\n",
    "total_count += labels.size (0)\n",
    "\n",
    "epoch_acc = total_acc / total_count\n",
    "epoch_loss = sum(losses) / len(losses)\n",
    "return epoch_acc , epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(train_data.classes)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available () else 'cpu')\n",
    "                        \n",
    "lenet_model = LeNetClassifier(num_classes)\n",
    "lenet_model.to(device)\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss ()\n",
    "learning_rate = 2e-4\n",
    "optimizer = optim.Adam(lenet_model.parameters (), learning_rate)\n",
    "\n",
    "num_epochs = 10\n",
    "save_model = './model'\n",
    "\n",
    "train_accs , train_losses = [], []\n",
    "eval_accs , eval_losses = [], []\n",
    "best_loss_eval = 100\n",
    "\n",
    "for epoch in range(1, num_epochs +1):\n",
    "epoch_start_time = time.time()\n",
    "# Training\n",
    "train_acc , train_loss = train(lenet_model , optimizer , criterion , train_dataloader ,device , epoch , log_interval =10)\n",
    "train_accs.append(train_acc)\n",
    "train_losses.append(train_loss)\n",
    "\n",
    "# Evaluation\n",
    "eval_acc , eval_loss = evaluate(lenet_model , criterion , valid_dataloader)\n",
    "eval_accs.append(eval_acc)\n",
    "eval_losses.append(eval_loss)\n",
    "\n",
    "# Save best model\n",
    "if eval_loss < best_loss_eval:\n",
    "torch.save(lenet_model.state_dict (), save_model + '/lenet_model.pt')\n",
    "\n",
    "# Print loss , acc end epoch\n",
    "print(\"-\" * 59)\n",
    "print(\n",
    "\"| End of epoch {:3d} | Time: {:5.2f}s | Train Accuracy {:8.3f} | Train Loss{:8.3f} \"\n",
    "\"| Valid Accuracy {:8.3f} | Valid Loss {:8.3f} \".format(\n",
    "epoch , time.time() - epoch_start_time , train_acc , train_loss , eval_acc ,eval_loss\n",
    ")\n",
    ")\n",
    "print(\"-\" * 59)\n",
    "\n",
    "# Load best model\n",
    "lenet_model.load_state_dict(torch.load(save_model + '/lenet_model.pt'))\n",
    "lenet_model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ĐÁNH GIÁ MÔ HÌNH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_acc , test_loss = evaluate(lenet_model , criterion , test_dataloader)\n",
    "test_acc , test_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TRIỂN KHAI MÔ HÌNH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dựa trên mô hình đã huấn luyện và thư viện streamlit để triển khai ứng dụng:\n",
    "1. Link Streamlit\n",
    "2. Github"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
