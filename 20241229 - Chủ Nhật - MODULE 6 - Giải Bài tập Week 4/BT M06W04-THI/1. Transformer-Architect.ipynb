{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "INPUT EMBEDDING, POSITIONAL ENCODING (nhập các thông số đầu vào)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TokenAndPositionEmbedding(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, max_length, device='cpu'):\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        self.word_emb = nn.Embedding(\n",
    "        num_embeddings=vocab_size,\n",
    "        embedding_dim=embed_dim\n",
    "        )\n",
    "        self.pos_emb = nn.Embedding(\n",
    "        num_embeddings=max_length,\n",
    "        embedding_dim=embed_dim\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        N, seq_len = x.size()\n",
    "        positions = torch.arange(0, seq_len).expand(N, seq_len).to(self.device)\n",
    "        output1 = self.word_emb(x)\n",
    "        output2 = self.pos_emb(positions)\n",
    "        output = output1 + output2\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ENCODER (Học từ dữ liệu đầu vào (không sinh ra thêm gì hết, chỉ học những cái đang có rồi phân loại, xem tính liên qua thôi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerEncoderBlock(nn.Module):\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.attn = nn.MultiheadAttention(\n",
    "            embed_dim=embed_dim,\n",
    "            num_heads=num_heads,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.ffn = nn.Sequential(\n",
    "            nn.Linear(in_features=embed_dim, out_features=ff_dim, bias=True),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=ff_dim, out_features=embed_dim, bias=True)\n",
    "        )\n",
    "        self.layernorm_1 = nn.LayerNorm(normalized_shape=embed_dim, eps=1e-6)\n",
    "        self.layernorm_2 = nn.LayerNorm(normalized_shape=embed_dim, eps=1e-6)\n",
    "        self.dropout_1 = nn.Dropout(p=dropout)\n",
    "        self.dropout_2 = nn.Dropout(p=dropout)\n",
    "\n",
    "    def forward(self, query, key, value):\n",
    "        attn_output, _ = self.attn(query, key, value)\n",
    "        attn_output = self.dropout_1(attn_output)\n",
    "        out_1 = self.layernorm_1(query + attn_output)\n",
    "        ffn_output = self.ffn(out_1)\n",
    "        ffn_output = self.dropout_2(ffn_output)\n",
    "        out_2 = self.layernorm_2(out_1 + ffn_output)\n",
    "        return out_2\n",
    "\n",
    "class TransformerEncoder(nn.Module):\n",
    "    def __init__(self,\n",
    "                 src_vocab_size, embed_dim, max_length, num_layers, num_heads, ff_dim,dropout=0.1, device='cpu'\n",
    "        ):\n",
    "        super().__init__()\n",
    "        self.embedding = TokenAndPositionEmbedding(\n",
    "            src_vocab_size, embed_dim, max_length, device\n",
    "        )\n",
    "        self.layers = nn.ModuleList(\n",
    "            [\n",
    "                TransformerEncoderBlock(\n",
    "                    embed_dim, num_heads, ff_dim, dropout\n",
    "                ) for i in range(num_layers)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = self.embedding(x)\n",
    "        for layer in self.layers:\n",
    "            output = layer(output, output, output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DECODER "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerDecoderBlock(nn.Module):\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.attn = nn.MultiheadAttention(\n",
    "            embed_dim=embed_dim,\n",
    "            num_heads=num_heads,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.cross_attn = nn.MultiheadAttention(\n",
    "            embed_dim=embed_dim,\n",
    "            num_heads=num_heads,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.ffn = nn.Sequential(\n",
    "            nn.Linear(in_features=embed_dim, out_features=ff_dim, bias=True),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=ff_dim, out_features=embed_dim, bias=True)\n",
    "        )\n",
    "        self.layernorm_1 = nn.LayerNorm(normalized_shape=embed_dim, eps=1e-6)\n",
    "        self.layernorm_2 = nn.LayerNorm(normalized_shape=embed_dim, eps=1e-6)\n",
    "        self.layernorm_3 = nn.LayerNorm(normalized_shape=embed_dim, eps=1e-6)\n",
    "        self.dropout_1 = nn.Dropout(p=dropout)\n",
    "        self.dropout_2 = nn.Dropout(p=dropout)\n",
    "        self.dropout_3 = nn.Dropout(p=dropout)\n",
    "\n",
    "    def forward(self, x, enc_output, src_mask, tgt_mask):\n",
    "        attn_output, _ = self.attn(x, x, x, attn_mask=tgt_mask)\n",
    "        attn_output = self.dropout_1(attn_output)\n",
    "        out_1 = self.layernorm_1(x + attn_output)\n",
    "\n",
    "        attn_output, _ = self.cross_attn(\n",
    "        out_1, enc_output, enc_output, attn_mask=src_mask\n",
    "        )\n",
    "        attn_output = self.dropout_2(attn_output)\n",
    "        out_2 = self.layernorm_2(out_1 + attn_output)\n",
    "\n",
    "        ffn_output = self.ffn(out_2)\n",
    "        ffn_output = self.dropout_3(ffn_output)\n",
    "        out_3 = self.layernorm_3(out_2 + ffn_output)\n",
    "        return out_3\n",
    "\n",
    "class TransformerDecoder(nn.Module):\n",
    "    def __init__(self,\n",
    "            tgt_vocab_size, embed_dim, max_length, num_layers, num_heads, ff_dim,\n",
    "            dropout=0.1, device='cpu'\n",
    "        ):\n",
    "        super().__init__()\n",
    "        self.embedding = TokenAndPositionEmbedding(\n",
    "            tgt_vocab_size, embed_dim, max_length, device\n",
    "        )\n",
    "        self.layers = nn.ModuleList(\n",
    "            [\n",
    "                TransformerDecoderBlock(\n",
    "                    embed_dim, num_heads, ff_dim, dropout\n",
    "                ) for i in range(num_layers)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def forward(self, x, enc_output, src_mask, tgt_mask):\n",
    "        output = self.embedding(x)\n",
    "        for layer in self.layers:\n",
    "            output = layer(output, enc_output, src_mask, tgt_mask)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TRANSFORMER(tạo mô hình truy vấn transformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self,\n",
    "                src_vocab_size, tgt_vocab_size,\n",
    "                embed_dim, max_length, num_layers, num_heads, ff_dim,\n",
    "                dropout=0.1, device='cpu'\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        self.encoder = TransformerEncoder(\n",
    "            src_vocab_size, embed_dim, max_length, num_layers, num_heads, ff_dim\n",
    "        )\n",
    "        self.decoder = TransformerDecoder(\n",
    "            tgt_vocab_size, embed_dim, max_length, num_layers, num_heads, ff_dim\n",
    "        )\n",
    "        self.fc = nn.Linear(embed_dim, tgt_vocab_size)\n",
    "\n",
    "    def generate_mask(self, src, tgt):\n",
    "        src_seq_len = src.shape[1]\n",
    "        tgt_seq_len = tgt.shape[1]\n",
    "\n",
    "        src_mask = torch.zeros(\n",
    "            (src_seq_len, src_seq_len),\n",
    "            device=self.device).type(torch.bool)\n",
    "\n",
    "        tgt_mask = (torch.triu(torch.ones(\n",
    "            (tgt_seq_len, tgt_seq_len),\n",
    "            device=self.device)\n",
    "        ) == 1).transpose(0, 1)\n",
    "        tgt_mask = tgt_mask.float().masked_fill(\n",
    "            tgt_mask == 0, float('-inf')).masked_fill(tgt_mask == 1, float(0.0))\n",
    "        return src_mask, tgt_mask\n",
    "\n",
    "    def forward(self, src, tgt):\n",
    "        src_mask, tgt_mask = self.generate_mask(src, tgt)\n",
    "        enc_output = self.encoder(src)\n",
    "        dec_output = self.decoder(tgt, enc_output, src_mask, tgt_mask)\n",
    "        output = self.fc(dec_output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "THỬ NGHIỆM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 100, 2000])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 128\n",
    "src_vocab_size = 1000\n",
    "tgt_vocab_size = 2000\n",
    "embed_dim = 200\n",
    "max_length = 100\n",
    "num_layers = 2\n",
    "num_heads = 4\n",
    "ff_dim = 256\n",
    "\n",
    "model = Transformer(\n",
    "    src_vocab_size, tgt_vocab_size,\n",
    "    embed_dim, max_length, num_layers, num_heads, ff_dim\n",
    ")\n",
    "\n",
    "src = torch.randint(\n",
    "    high=2,\n",
    "    size=(batch_size, max_length),\n",
    "    dtype=torch.int64\n",
    ")\n",
    "\n",
    "tgt = torch.randint(\n",
    "    high=2,\n",
    "    size=(batch_size, max_length),\n",
    "    dtype=torch.int64\n",
    ")\n",
    "\n",
    "prediction = model(src, tgt)\n",
    "prediction.shape # batch_size x max_length x tgt_vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
